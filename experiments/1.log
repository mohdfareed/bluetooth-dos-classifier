[2024-04-11 00:32:58,484] Starting experiment 1

[2024-04-11 00:32:59,889] Training data:
                 No.          Time         Length      Type
count  998391.000000  9.983910e+05  998391.000000  998391.0
mean   499196.000000  4.621494e+05      20.064474       1.0
std    288210.800641  4.679402e+05      12.352341       0.0
min         1.000000  0.000000e+00       4.000000       1.0
25%    249598.500000  2.276077e+03       8.000000       1.0
50%    499196.000000  6.853190e+05      16.000000       1.0
75%    748793.500000  8.540422e+05      32.000000       1.0
max    998391.000000  1.198804e+06     255.000000       1.0

[2024-04-11 00:32:59,904] Testing data:
                 No.           Time         Length      Type
count  251708.000000  251708.000000  251708.000000  251708.0
mean   125854.500000    1071.256077      20.006591       1.0
std     72661.985116     638.578923      12.006976       0.0
min         1.000000       0.000000       5.000000       1.0
25%     62927.750000     601.485238       8.000000       1.0
50%    125854.500000    1050.763037      16.000000       1.0
75%    188781.250000    1669.751179      32.000000       1.0
max    251708.000000    2094.097550      46.000000       1.0

[2024-04-11 00:33:11,486] TF-IDF Vocabulary size: 609
[2024-04-11 00:33:11,488] One-Hot Encoding unique categories: 6
[2024-04-11 00:33:11,490] Standard Scaling mean: 22.7672
[2024-04-11 00:33:11,490] Standard Scaling std: 14.1469
[2024-04-11 00:33:11,491] Feature Hashing features count: 20
[2024-04-11 00:33:11,492] Total number of features: 657

[2024-04-11 00:37:13,431]       Iter       Train Loss   Remaining Time
[2024-04-11 00:37:15,189]          1           0.7654            2.90m
[2024-04-11 00:37:16,828]          2           0.6565            2.77m
[2024-04-11 00:37:18,737]          3           0.5758            2.86m
[2024-04-11 00:37:21,000]          4           0.5121            3.03m
[2024-04-11 00:37:22,744]          5           0.4581            2.95m
[2024-04-11 00:37:24,335]          6           0.4140            2.85m
[2024-04-11 00:37:25,969]          7           0.3766            2.78m
[2024-04-11 00:37:27,658]          8           0.3440            2.73m
[2024-04-11 00:37:29,291]          9           0.3160            2.67m
[2024-04-11 00:37:31,089]         10           0.2917            2.65m
[2024-04-11 00:37:48,596]         20           0.1581            2.34m
[2024-04-11 00:38:05,197]         30           0.0744            2.01m
[2024-04-11 00:38:23,099]         40           0.0528            1.74m
[2024-04-11 00:38:40,230]         50           0.0317            1.45m
[2024-04-11 00:38:57,768]         60           0.0204            1.16m
[2024-04-11 00:39:15,176]         70           0.0173           52.18s
[2024-04-11 00:39:32,658]         80           0.0140           34.81s
[2024-04-11 00:39:49,100]         90           0.0126           17.30s
[2024-04-11 00:40:07,300]        100           0.0086            0.00s
[2024-04-11 00:40:07,305] Model trained complete

[2024-04-11 00:40:19,959] Train accuracy: 0.8341019057652395
[2024-04-11 00:40:19,993] Confusion matrix:
[[ 63467   1863]
 [ 50733 200975]]
[2024-04-11 00:40:20,292] Classification report:
              precision    recall  f1-score   support

           0       0.56      0.97      0.71     65330
           1       0.99      0.80      0.88    251708

    accuracy                           0.83    317038
   macro avg       0.77      0.88      0.80    317038
weighted avg       0.90      0.83      0.85    317038
