{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bluetooth DoS Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from joblib import dump, load\n",
    "from scipy.sparse import csr_matrix, hstack, load_npz, save_npz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# ensure that the working directory is the same as the notebook\n",
    "notebook_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "os.chdir(notebook_path)\n",
    "\n",
    "# create directories\n",
    "if not os.path.exists(\"data\"):\n",
    "    raise Exception(\"Data directory not found.\")\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.makedirs(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "ATTACK_TRAIN = \"data/dos_train.csv\"\n",
    "BENIGN_TRAIN = \"data/benign_train.csv\"\n",
    "ATTACK_TEST = \"data/dos_test.csv\"\n",
    "BENIGN_TEST = \"data/benign_test.csv\"\n",
    "\n",
    "# preprocessed data paths\n",
    "PREPROCESSED_TRAIN = \"data/preprocessed_train.csv\"\n",
    "PREPROCESSED_TEST = \"data/preprocessed_test.csv\"\n",
    "LABELS_TRAIN = \"data/labels_train.csv\"\n",
    "LABELS_TEST = \"data/labels_test.csv\"\n",
    "\n",
    "# features paths\n",
    "FEATURES_TEST = \"data/features_test.csv\"\n",
    "FEATURES_TRAIN = \"data/features_train.csv\"\n",
    "\n",
    "# models paths\n",
    "VECTORIZER_MODEL = \"models/vectorizer.joblib\"\n",
    "ENCODER_MODEL = \"models/encoder.joblib\"\n",
    "SCALER_MODEL = \"models/scaler.joblib\"\n",
    "GBM_MODEL = \"models/gbm.joblib\"  # gradient boosting machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is obtained from the following link:\n",
    "https://www.unb.ca/cic/datasets/iomt-dataset-2024.html\n",
    "\n",
    "The specific dataset used is the \"Bluetooth\" dataset. The dataset is in `.pcap` format. The dataset is first converted to `.csv` format using the `tshark` command line tool (WireShark can also be used). The resulting dataset files are:\n",
    "\n",
    "- `data/benign_test.csv`\n",
    "- `data/benign_train.csv`\n",
    "- `data/dos_test.csv`\n",
    "- `data/dos_train.csv`\n",
    "\n",
    "The original dataset are compressed in their `.pcap` format at `data/bl_dataset.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "attack_train = pd.read_csv(ATTACK_TRAIN)\n",
    "benign_train = pd.read_csv(BENIGN_TRAIN)\n",
    "attack_test = pd.read_csv(ATTACK_TEST)\n",
    "benign_test = pd.read_csv(BENIGN_TEST)\n",
    "\n",
    "# add type column indicating attack or benign\n",
    "attack_train[\"Type\"] = 1\n",
    "attack_test[\"Type\"] = 1\n",
    "benign_train[\"Type\"] = 0\n",
    "benign_test[\"Type\"] = 0\n",
    "\n",
    "# combine datasets\n",
    "train_dataset = pd.concat([attack_train, benign_train], ignore_index=True)\n",
    "test_dataset = pd.concat([attack_test, benign_test], ignore_index=True)\n",
    "\n",
    "# shuffle datasets\n",
    "train_dataset = train_dataset.sample(frac=1).reset_index(drop=True)\n",
    "test_dataset = test_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# generate labels\n",
    "train_labels = train_dataset[\"Type\"]\n",
    "train_dataset.drop(columns=[\"Type\"], inplace=True)\n",
    "test_labels = test_dataset[\"Type\"]\n",
    "test_dataset.drop(columns=[\"Type\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "                 No.          Time         Length      Type\n",
      "count  998391.000000  9.983910e+05  998391.000000  998391.0\n",
      "mean   499196.000000  4.621494e+05      20.064474       1.0\n",
      "std    288210.800641  4.679402e+05      12.352341       0.0\n",
      "min         1.000000  0.000000e+00       4.000000       1.0\n",
      "25%    249598.500000  2.276077e+03       8.000000       1.0\n",
      "50%    499196.000000  6.853190e+05      16.000000       1.0\n",
      "75%    748793.500000  8.540422e+05      32.000000       1.0\n",
      "max    998391.000000  1.198804e+06     255.000000       1.0\n",
      "\n",
      "Testing data:\n",
      "                 No.           Time         Length      Type\n",
      "count  251708.000000  251708.000000  251708.000000  251708.0\n",
      "mean   125854.500000    1071.256077      20.006591       1.0\n",
      "std     72661.985116     638.578923      12.006976       0.0\n",
      "min         1.000000       0.000000       5.000000       1.0\n",
      "25%     62927.750000     601.485238       8.000000       1.0\n",
      "50%    125854.500000    1050.763037      16.000000       1.0\n",
      "75%    188781.250000    1669.751179      32.000000       1.0\n",
      "max    251708.000000    2094.097550      46.000000       1.0\n"
     ]
    }
   ],
   "source": [
    "# summary statistics\n",
    "print(f\"Training data:\\n{attack_train.describe()}\\n\")\n",
    "print(f\"Testing data:\\n{attack_test.describe()}\")\n",
    "\n",
    "# write modified dataset to files\n",
    "train_dataset.to_csv(PREPROCESSED_TRAIN, index=False)\n",
    "test_dataset.to_csv(PREPROCESSED_TEST, index=False)\n",
    "np.save(LABELS_TRAIN, train_labels)\n",
    "np.save(LABELS_TEST, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_hashing(dataset, column, n_features=20):\n",
    "    \"\"\"Applies feature hashing to a specified column of the dataset.\"\"\"\n",
    "    hasher = FeatureHasher(n_features=n_features, input_type=\"string\")\n",
    "    hashed_features = hasher.transform(\n",
    "        dataset[column].apply(lambda x: [str(x)])\n",
    "    )\n",
    "    return hashed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying TF-IDF vectorization...\n",
      "Applying one-hot encoding...\n",
      "Applying standard scaling...\n",
      "Applying feature hashing...\n"
     ]
    }
   ],
   "source": [
    "# apply tf-idf vectorization to Info column\n",
    "print(\"Applying TF-IDF vectorization...\")\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_info = vectorizer.fit_transform(train_dataset[\"Info\"])\n",
    "test_info = vectorizer.transform(test_dataset[\"Info\"])\n",
    "\n",
    "# apply one-hot encoding to Protocol column\n",
    "print(\"Applying one-hot encoding...\")\n",
    "encoder = OneHotEncoder()\n",
    "train_protocol = encoder.fit_transform(train_dataset[[\"Protocol\"]])\n",
    "test_protocol = encoder.transform(test_dataset[[\"Protocol\"]])\n",
    "\n",
    "# apply standard scaling to Length column\n",
    "print(\"Applying standard scaling...\")\n",
    "scaler = StandardScaler()\n",
    "train_length = scaler.fit_transform(train_dataset[[\"Length\"]])\n",
    "test_length = scaler.transform(test_dataset[[\"Length\"]])\n",
    "\n",
    "# apply feature hashing to Source and Destination columns\n",
    "print(\"Applying feature hashing...\")\n",
    "train_source = apply_feature_hashing(train_dataset, \"Source\")\n",
    "test_source = apply_feature_hashing(test_dataset, \"Source\")\n",
    "train_destination = apply_feature_hashing(train_dataset, \"Destination\")\n",
    "test_destination = apply_feature_hashing(test_dataset, \"Destination\")\n",
    "\n",
    "# combine features\n",
    "train_features = hstack(\n",
    "    [\n",
    "        csr_matrix(train_dataset[[\"Time\"]]),\n",
    "        train_source,\n",
    "        train_destination,\n",
    "        train_protocol,\n",
    "        csr_matrix(train_length),\n",
    "        train_info,\n",
    "    ]\n",
    ")\n",
    "test_features = hstack(\n",
    "    [\n",
    "        csr_matrix(test_dataset[[\"Time\"]]),\n",
    "        test_source,\n",
    "        test_destination,\n",
    "        test_protocol,\n",
    "        csr_matrix(test_length),\n",
    "        test_info,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vocabulary size: 609\n",
      "One-Hot Encoding unique categories: 6\n",
      "Standard Scaling mean: 22.7672\n",
      "Standard Scaling std: 14.1469\n",
      "Feature Hashing features count: 20\n",
      "Total number of features: 657\n"
     ]
    }
   ],
   "source": [
    "# report feature extraction results\n",
    "print(f\"TF-IDF Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"One-Hot Encoding unique categories: {len(encoder.categories_[0])}\")  # type: ignore\n",
    "print(f\"Standard Scaling mean: {scaler.mean_[0]:.4f}\")  # type: ignore\n",
    "print(f\"Standard Scaling std: {scaler.scale_[0]:.4f}\")  # type: ignore\n",
    "print(f\"Feature Hashing features count: {train_source.shape[1]}\")\n",
    "print(f\"Total number of features: {train_features.shape[1]}\")\n",
    "\n",
    "# write features and models to files\n",
    "save_npz(FEATURES_TRAIN, train_features)\n",
    "save_npz(FEATURES_TEST, test_features)\n",
    "dump(vectorizer, VECTORIZER_MODEL);\n",
    "dump(encoder, ENCODER_MODEL);\n",
    "dump(scaler, SCALER_MODEL);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.7654            2.87m\n",
      "         2           0.6565            2.83m\n",
      "         3           0.5758            2.81m\n",
      "         4           0.5121            2.75m\n",
      "         5           0.4581            2.69m\n",
      "         6           0.4140            2.64m\n",
      "         7           0.3766            2.64m\n",
      "         8           0.3440            2.59m\n",
      "         9           0.3160            2.56m\n",
      "        10           0.2917            2.54m\n",
      "        20           0.1581            2.35m\n",
      "        30           0.0744            2.09m\n",
      "        40           0.0528            1.84m\n",
      "        50           0.0317            1.52m\n",
      "        60           0.0204            1.21m\n",
      "        70           0.0173           54.89s\n",
      "        80           0.0140           36.53s\n",
      "        90           0.0126           18.23s\n",
      "       100           0.0086            0.00s\n"
     ]
    }
   ],
   "source": [
    "# load features (to prevent forced extraction to define variables)\n",
    "train_features = load_npz(FEATURES_TRAIN)\n",
    "train_labels = np.load(LABELS_TRAIN)\n",
    "\n",
    "# train model\n",
    "model = GradientBoostingClassifier(verbose=1)\n",
    "model.fit(train_features, train_labels)  # type: ignore\n",
    "\n",
    "# write model to file\n",
    "dump(model, GBM_MODEL);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8341019057652395\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 63467   1863]\n",
      " [ 50733 200975]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71     65330\n",
      "           1       0.99      0.80      0.88    251708\n",
      "\n",
      "    accuracy                           0.83    317038\n",
      "   macro avg       0.77      0.88      0.80    317038\n",
      "weighted avg       0.90      0.83      0.85    317038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model and features (to prevent forced training to define variables)\n",
    "model = load(GBM_MODEL)\n",
    "test_features = load_npz(FEATURES_TEST)\n",
    "test_labels = np.load(LABELS_TEST)\n",
    "\n",
    "# evaluate model\n",
    "predictions = model.predict(test_features)  # type: ignore\n",
    "accuracy = metrics.accuracy_score(test_labels, predictions)\n",
    "print(f\"Train accuracy: {accuracy}\\n\")\n",
    "conf_matrix = metrics.confusion_matrix(test_labels, predictions)\n",
    "print(f\"Confusion matrix:\\n{conf_matrix}\\n\")\n",
    "report = metrics.classification_report(test_labels, predictions)\n",
    "print(f\"Classification report:\\n{report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
